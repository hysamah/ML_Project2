{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/ml/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_neg.txt', 'train_pos.txt', 'sample_submission.csv', 'test_data.txt', 'train_neg_clean.txt', 'train_pos_clean.txt', 'test_data_clean.txt']\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from course_helpers import *\n",
    "from helpers import *\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "from torch.nn import Sequential, Module, LSTM, ReLU, Linear, Sigmoid, Dropout, Embedding\n",
    "import torchvision\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from datetime import datetime\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "##data preprocessing \n",
    "DATA_PATH = 'twitter-datasets'\n",
    "Dataset = read(DATA_PATH)\n",
    "\n",
    "#@title read dataset file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset = clean(Dataset)\n",
    "# save_to_file(Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash course_helpers.sh\n",
    "##Run this in terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_cut = 'vocab_cut.txt'\n",
    "vocab_pkl = 'vocab_pkl.pkl'\n",
    "coco_pkl = 'coco_pkl.pkl'\n",
    "embd = 'embeddings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle_vocab(vocab_cut, vocab_pkl)\n",
    "# cooc_(vocab_pkl, DATA_PATH, coco_pkl)\n",
    "# glove(coco_pkl, embd)\n",
    "# with open(coco_pkl, \"rb\") as f:\n",
    "#         cooc = pickle.load(f)\n",
    "# print(cooc.shape)\n",
    "# with open(vocab_pkl, \"rb\") as f:\n",
    "#         vocab = pickle.load(f)\n",
    "# print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17971, 20)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embedding = np.load(embd+'.npy')\n",
    "print(embedding.shape)\n",
    "glove_embd = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_pos, train_neg, test_set = read_data(Dataset)\n",
    "# train_set = pd.concat([train_pos, train_neg],  axis=0, ignore_index=True)\n",
    "# train_set = pd.concat([train_set.drop(labels='sentiment', axis=1), train_set['sentiment']], axis = 1)\n",
    "\n",
    "# train_set.loc[:, train_set.columns!='sentiment'] = train_set.applymap(lambda x: find_token(x, vocab))\n",
    "# test_set2 =  test_set.applymap(lambda x: find_token(x, vocab))\n",
    "# train_set.to_csv('train_set_token.csv', index= False)\n",
    "# test_set2.to_csv('test_set_token.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv('test_set_token.csv')\n",
    "train_set = pd.read_csv('train_set_token.csv', )\n",
    "num_embeddings  = glove_embd.shape[0]\n",
    "embed_dim = glove_embd.shape[1]\n",
    "max_len = train_set.shape[1]-1\n",
    "batch_size = 16\n",
    "n_batches = train_set.shape[0]/batch_size\n",
    "\n",
    "X_train = train_set.loc[:, train_set.columns!='sentiment']\n",
    "Y_train = train_set['sentiment']\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "glove_embd = torch.tensor(glove_embd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 144 artists>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#histogram of number of tokens per tweet\n",
    "histogram = X_train\n",
    "histogram['num_uniq'] = histogram.apply(pd.Series.nunique, axis=1)\n",
    "histogram = histogram['num_uniq']\n",
    "hist,bins = np.histogram(histogram,bins = [i for i in range(0, 145, 1)]) \n",
    "plt.bar(bins[:-1], hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split = (X_train.shape[0]*0.2)%batch_size\n",
    "data_split  = X_train.shape[0]*0.2 - data_split\n",
    "data_split=data_split/2\n",
    "remd = -data_split + X_train.shape[0] - data_split\n",
    "addedv = remd%data_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val =  torch.tensor(pd.concat([X_train[:int(data_split)], X_train[-int(data_split):]],  axis=0, ignore_index=True).reset_index(drop=True).to_numpy()).to(device)\n",
    "Y_val =  torch.tensor(pd.concat([Y_train[:int(data_split)], Y_train[-int(data_split):]],  axis=0, ignore_index=True).reset_index(drop=True).to_numpy(dtype='float32')).to(device)\n",
    "X_train = torch.tensor(X_train[int(data_split+addedv):-int(data_split)].reset_index(drop=True).to_numpy()).to(device)\n",
    "Y_train =  torch.tensor(Y_train[int(data_split+addedv):-int(data_split)].reset_index(drop=True).to_numpy(dtype='float32')).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test =  torch.tensor(test_set.to_numpy()).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class make_torch_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=[]):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inp = self.encodings[idx]\n",
    "        label = self.labels[idx]\n",
    "        return inp, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings)\n",
    "\n",
    "class make_torch_testset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inp = self.encodings[idx]\n",
    "        return inp\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings)\n",
    "\n",
    "train_dataset = make_torch_dataset(X_train, Y_train)\n",
    "val_dataset = make_torch_dataset(X_val, Y_val)\n",
    "test_dataset = make_torch_testset(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 143552 instances\n",
      "Validation set has 35888 instances\n",
      "Test set has 10000 instances\n"
     ]
    }
   ],
   "source": [
    "# Create data loaders for our datasets; shuffle for training, not for validation\n",
    "training_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "validation_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "# Report split sizes\n",
    "print('Training set has {} instances'.format(len(train_dataset)))\n",
    "print('Validation set has {} instances'.format(len(val_dataset)))\n",
    "print('Test set has {} instances'.format(len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class lstm_classifier(Module):\n",
    "    def __init__(self, num_embeddings, embed_dim, glove_embd, max_len) -> None:\n",
    "        super().__init__()\n",
    "        self.emd =  Embedding(num_embeddings= num_embeddings, embedding_dim= embed_dim, _weight=glove_embd)\n",
    "        self.lstm1 = LSTM(input_size = embed_dim, hidden_size = 256, bidirectional = True, batch_first  = True)\n",
    "        self.lstm2 = LSTM(input_size = 512, hidden_size = 150, bidirectional = True,  batch_first  = True)\n",
    "        self.fc1 = Linear(300,128)\n",
    "        self.drp = Dropout(0.1)\n",
    "        self.fc2 = Linear(128, 64)\n",
    "        self.fc3 = Linear(64,1)\n",
    "        self.reg = Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.emd(x)\n",
    "        x = x.to(torch.float32)\n",
    "        x, states = self.lstm1(x)\n",
    "        x, states = self.lstm2(x)\n",
    "        x = F.relu(self.fc1(x[:,0]))\n",
    "        x = self.drp(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.reg(x)\n",
    "        x = x.reshape(x.shape[0])\n",
    "\n",
    "        return x\n",
    "model = lstm_classifier(num_embeddings, embed_dim, glove_embd, max_len).to(device)\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "    running_accuracy = 0.0\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "\n",
    "    with tqdm(training_loader, unit=\"batch\") as tepoch:\n",
    "        for i, data in enumerate(tepoch):\n",
    "            tepoch.set_description(f\"Epoch {epoch_index}\")\n",
    "\n",
    "\n",
    "    #for i, data in enumerate(tqdm(training_loader), unit= \"batches\", ):\n",
    "            # Every data instance is an input + label pair\n",
    "            inputs, labels = data\n",
    "\n",
    "            # Zero your gradients for every batch!\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "\n",
    "            # Make predictions for this batch\n",
    "            outputs = model(inputs)\n",
    "            accuracy  = accuracy_score(labels.cpu(), [1 if x > 0.5 else 0 for x in outputs.cpu()])\n",
    "            # Compute the loss and its gradients\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            # Adjust learning weights\n",
    "            optimizer.step()\n",
    "            # Gather data and report\n",
    "            running_loss += loss.item()\n",
    "            running_accuracy += accuracy\n",
    "\n",
    "            tepoch.set_postfix(loss=loss.item(), accuracy = accuracy)\n",
    "            if i % batch_size == batch_size-1:\n",
    "                last_loss = running_loss / batch_size # loss per batch\n",
    "                #print('  epoch {} batch {} loss: {}'.format(epoch_index, (i + 1)/batch_size, last_loss))\n",
    "                tb_x = epoch_index * len(training_loader) + i + 1\n",
    "                #print(tb_x)\n",
    "                tb_writer.add_scalar('Loss/train', last_loss, global_step = tb_x)\n",
    "                running_loss = 0.\n",
    "\n",
    "    return last_loss, running_accuracy/i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss, acc = train_one_epoch(epoch, writer)\n",
    "\n",
    "    # # We don't need gradients on to do reporting\n",
    "    model.train(False)\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    running_vacc = 0.0\n",
    "    for i, vdata in enumerate(validation_loader):\n",
    "        vinputs, vlabels = vdata\n",
    "        voutputs = model(vinputs).detach()\n",
    "        vacc  = accuracy_score(vlabels.cpu(), [1 if x > 0.5 else 0 for x in voutputs.cpu()])\n",
    "        running_vacc += vacc\n",
    "        vloss = loss_fn(voutputs, vlabels)\n",
    "        running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    avg_vacc = running_vacc / (i + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch + 1)\n",
    "    writer.add_scalars('Training vs. Validation Accuracy',\n",
    "                    { 'Training' : acc, 'Validation' : avg_vacc },\n",
    "                    epoch + 1)\n",
    "    #writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'model_{}_{}'.format(timestamp, epoch)\n",
    "        torch.save(model.state_dict(), model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(False)\n",
    "preds_test = []\n",
    "for i, vdata in enumerate(test_loader):\n",
    "    vinputs = vdata\n",
    "    voutputs = model(vinputs).detach()\n",
    "    preds_test.extend(voutputs.cpu())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-10000.0\n"
     ]
    }
   ],
   "source": [
    "preds = np.ones_like(preds_test)\n",
    "preds[np.where(np.array(preds_test)<0.5)] = -1\n",
    "preds = pd.DataFrame(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def create_csv_submission(ids, y_pred, name):\n",
    "    \"\"\"\n",
    "    Creates an output file in .csv format for submission to Kaggle or AIcrowd\n",
    "    Arguments: ids (event ids associated with each prediction)\n",
    "               y_pred (predicted class labels)\n",
    "               name (string name of .csv output file to be created)\n",
    "    \"\"\"\n",
    "    with open(name, \"w\") as csvfile:\n",
    "        fieldnames = [\"Id\", \"Prediction\"]\n",
    "        writer = csv.DictWriter(csvfile, delimiter=\",\", fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for r1, r2 in zip(ids, y_pred):\n",
    "            writer.writerow({\"Id\": int(r1)+1, \"Prediction\": int(r2)})\n",
    "\n",
    "create_csv_submission(preds.index.values.tolist(), np.asarray(preds), \"____test____.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_cut.txt\n",
      "train_neg_full.txt\n",
      "train_pos_full.txt\n",
      "train_pos_full_clean.txt\n",
      "vocab_full.txt\n",
      "test_data_clean.txt\n",
      "train_neg_full_clean.txt\n",
      "Training set has 1778688 instances\n",
      "Validation set has 444672 instances\n",
      "Test set has 10000 instances\n",
      "EPOCH 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 6948/6948 [04:55<00:00, 23.52batch/s, accuracy=0.691, loss=0.576]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.6106715290807188 valid 0.6093485355377197\n",
      "EPOCH 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 6948/6948 [04:51<00:00, 23.85batch/s, accuracy=0.621, loss=0.653]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.6015164870768785 valid 0.6066562533378601\n",
      "EPOCH 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 6948/6948 [04:51<00:00, 23.80batch/s, accuracy=0.602, loss=0.623]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.5949465315788984 valid 0.6048341989517212\n",
      "EPOCH 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 6948/6948 [04:51<00:00, 23.83batch/s, accuracy=0.645, loss=0.615]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.5915771478321403 valid 0.6049190163612366\n",
      "EPOCH 5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 6948/6948 [04:52<00:00, 23.74batch/s, accuracy=0.656, loss=0.584]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.593359355116263 valid 0.6051402688026428\n",
      "EPOCH 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 6948/6948 [04:51<00:00, 23.87batch/s, accuracy=0.656, loss=0.624]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.5921900295652449 valid 0.6054492592811584\n"
     ]
    }
   ],
   "source": [
    "from course_helpers import *\n",
    "from helpers import *\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from torch.nn import Sequential, Module, LSTM, ReLU, Linear, Sigmoid, Dropout, Embedding, RNN\n",
    "import torchvision\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "import csv\n",
    "def create_csv_submission(ids, y_pred, name):\n",
    "    \"\"\"\n",
    "    Creates an output file in .csv format for submission to Kaggle or AIcrowd\n",
    "    Arguments: ids (event ids associated with each prediction)\n",
    "               y_pred (predicted class labels)\n",
    "               name (string name of .csv output file to be created)\n",
    "    \"\"\"\n",
    "    with open(name, \"w\") as csvfile:\n",
    "        fieldnames = [\"Id\", \"Prediction\"]\n",
    "        writer = csv.DictWriter(csvfile, delimiter=\",\", fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for r1, r2 in zip(ids, y_pred):\n",
    "            writer.writerow({\"Id\": int(r1)+1, \"Prediction\": int(r2)})\n",
    "\n",
    "\n",
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "    running_accuracy = 0.0\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "\n",
    "    with tqdm(training_loader, unit=\"batch\") as tepoch:\n",
    "        for i, data in enumerate(tepoch):\n",
    "            tepoch.set_description(f\"Epoch {epoch_index}\")\n",
    "\n",
    "\n",
    "    #for i, data in enumerate(tqdm(training_loader), unit= \"batches\", ):\n",
    "            # Every data instance is an input + label pair\n",
    "            inputs, labels = data\n",
    "\n",
    "            # Zero your gradients for every batch!\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "\n",
    "            # Make predictions for this batch\n",
    "            outputs = model(inputs)\n",
    "            accuracy  = accuracy_score(labels.cpu(), [1 if x > 0.5 else 0 for x in outputs.cpu()])\n",
    "            # Compute the loss and its gradients\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            # Adjust learning weights\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Gather data and report\n",
    "            running_loss += loss.item()\n",
    "            running_accuracy += accuracy\n",
    "\n",
    "            tepoch.set_postfix(loss=loss.item(), accuracy = accuracy)\n",
    "            if i % batch_size == batch_size-1:\n",
    "                last_loss = running_loss / batch_size # loss per batch\n",
    "                #print('  epoch {} batch {} loss: {}'.format(epoch_index, (i + 1)/batch_size, last_loss))\n",
    "                tb_x = epoch_index * len(training_loader) + i + 1\n",
    "                #print(tb_x)\n",
    "                tb_writer.add_scalar('Loss/train', last_loss, global_step = tb_x)\n",
    "                running_loss = 0.\n",
    "\n",
    "    return last_loss, running_accuracy/i\n",
    "\n",
    "\n",
    "class make_torch_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=[]):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inp = self.encodings[idx]\n",
    "        label = self.labels[idx]\n",
    "        return inp, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings)\n",
    "\n",
    "class make_torch_testset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inp = self.encodings[idx]\n",
    "        return inp\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings)\n",
    "\n",
    "class Blstm_classifier(Module):\n",
    "    def __init__(self, num_embeddings, embed_dim, glove_embd, max_len) -> None:\n",
    "        super().__init__()\n",
    "        self.emd =  Embedding(num_embeddings= num_embeddings, embedding_dim= embed_dim, _weight=glove_embd)\n",
    "        self.lstm1 = LSTM(input_size = embed_dim, hidden_size = 256, bidirectional = True, batch_first  = True)\n",
    "        self.lstm2 = LSTM(input_size = 512, hidden_size = 150, bidirectional = True,  batch_first  = True)\n",
    "        self.fc1 = Linear(300,128)\n",
    "        self.drp = Dropout(0.1)\n",
    "        self.fc2 = Linear(128, 64)\n",
    "        self.fc3 = Linear(64,1)\n",
    "        self.reg = Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.emd(x)\n",
    "        x = x.to(torch.float32)\n",
    "        x, states = self.lstm1(x)\n",
    "        x, states = self.lstm2(x)\n",
    "        x = F.relu(self.fc1(x[:,0]))\n",
    "        x = self.drp(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.reg(x)\n",
    "        x = x.reshape(x.shape[0])\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class RNN_classifier(Module):\n",
    "    def __init__(self, num_embeddings, embed_dim, glove_embd, max_len) -> None:\n",
    "        super().__init__()\n",
    "        self.emd =  Embedding(num_embeddings= num_embeddings, embedding_dim= embed_dim, _weight=glove_embd)\n",
    "        self.rnn1 = RNN(input_size = embed_dim, hidden_size = 256, batch_first = True)\n",
    "        self.fc1 = Linear(256,128)\n",
    "        self.drp = Dropout(0.1)\n",
    "        self.fc2 = Linear(128, 64)\n",
    "        self.fc3 = Linear(64,1)\n",
    "        self.reg = Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.emd(x)\n",
    "        x = x.to(torch.float32)\n",
    "        x, _ = self.rnn1(x)\n",
    "        x = F.relu(self.fc1(x[:,0]))\n",
    "        x = self.drp(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.reg(x)\n",
    "        x = x.reshape(x.shape[0])\n",
    "\n",
    "        return x\n",
    "class lstm_classifier(Module):\n",
    "    def __init__(self, num_embeddings, embed_dim, glove_embd, max_len) -> None:\n",
    "        super().__init__()\n",
    "        self.emd =  Embedding(num_embeddings= num_embeddings, embedding_dim= embed_dim, _weight=glove_embd)\n",
    "        self.lstm1 = LSTM(input_size = embed_dim, hidden_size = 256,batch_first  = True)\n",
    "        self.lstm2 = LSTM(input_size = 256, hidden_size = 150, batch_first  = True)\n",
    "        self.fc1 = Linear(150,128)\n",
    "        self.drp = Dropout(0.1)\n",
    "        self.fc2 = Linear(128, 64)\n",
    "        self.fc3 = Linear(64,1)\n",
    "        self.reg = Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.emd(x)\n",
    "        x = x.to(torch.float32)\n",
    "        x, _ = self.lstm1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = F.relu(self.fc1(x[:,0]))\n",
    "        x = self.drp(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.reg(x)\n",
    "        x = x.reshape(x.shape[0])\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "##data preprocessing \n",
    "DATA_PATH = 'full_data/'\n",
    "Dataset = read(DATA_PATH)\n",
    "\n",
    "\n",
    "embd = DATA_PATH+'embeddings_50'\n",
    "embedding = np.load(embd+'.npy')\n",
    "glove_embd = embedding\n",
    "\n",
    "\n",
    "test_set = pd.read_csv(DATA_PATH+'test_set_token.csv')\n",
    "train_set = pd.read_csv(DATA_PATH+'train_set_token_full.csv', )\n",
    "num_embeddings  = glove_embd.shape[0]\n",
    "embed_dim = glove_embd.shape[1]\n",
    "max_len = train_set.shape[1]-1\n",
    "batch_size = 256\n",
    "n_batches = train_set.shape[0]/batch_size\n",
    "\n",
    "X_train = train_set.loc[:, train_set.columns!='sentiment']\n",
    "Y_train = train_set['sentiment']\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "glove_embd = torch.tensor(glove_embd)\n",
    "\n",
    "data_split = (X_train.shape[0]*0.2)%batch_size\n",
    "data_split  = X_train.shape[0]*0.2 - data_split\n",
    "data_split=data_split/2\n",
    "remd = -data_split + X_train.shape[0] - data_split\n",
    "addedv = remd%data_split\n",
    "\n",
    "X_val =  torch.tensor(pd.concat([X_train[:int(data_split)], X_train[-int(data_split):]],  axis=0, ignore_index=True).reset_index(drop=True).to_numpy()).to(device)\n",
    "Y_val =  torch.tensor(pd.concat([Y_train[:int(data_split)], Y_train[-int(data_split):]],  axis=0, ignore_index=True).reset_index(drop=True).to_numpy(dtype='float32')).to(device)\n",
    "X_train = torch.tensor(X_train[int(data_split+addedv):-int(data_split)].reset_index(drop=True).to_numpy()).to(device)\n",
    "Y_train =  torch.tensor(Y_train[int(data_split+addedv):-int(data_split)].reset_index(drop=True).to_numpy(dtype='float32')).to(device)\n",
    "X_test =  torch.tensor(test_set.to_numpy()).to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = make_torch_dataset(X_train, Y_train)\n",
    "val_dataset = make_torch_dataset(X_val, Y_val)\n",
    "test_dataset = make_torch_testset(X_test)\n",
    "\n",
    "# Create data loaders for our datasets; shuffle for training, not for validation\n",
    "training_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "validation_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "# Report split sizes\n",
    "print('Training set has {} instances'.format(len(train_dataset)))\n",
    "print('Validation set has {} instances'.format(len(val_dataset)))\n",
    "print('Test set has {} instances'.format(len(test_dataset)))\n",
    "\n",
    "\n",
    "\n",
    "# initializing model and losses\n",
    "model = RNN_classifier(num_embeddings, embed_dim, glove_embd, max_len).to(device)\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[2,4], gamma=0.5)\n",
    "\n",
    "\n",
    "# starting main training loop\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('full_runs/fashion_trainer_{}'.format(timestamp))\n",
    "\n",
    "EPOCHS = 6\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss, acc = train_one_epoch(epoch, writer)\n",
    "    scheduler.step()\n",
    "\n",
    "    # # We don't need gradients on to do reporting\n",
    "    model.train(False)\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    running_vacc = 0.0\n",
    "    for i, vdata in enumerate(validation_loader):\n",
    "        vinputs, vlabels = vdata\n",
    "        voutputs = model(vinputs).detach()\n",
    "        vacc  = accuracy_score(vlabels.cpu(), [1 if x > 0.5 else 0 for x in voutputs.cpu()])\n",
    "        running_vacc += vacc\n",
    "        vloss = loss_fn(voutputs, vlabels)\n",
    "        running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    avg_vacc = running_vacc / (i + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation/Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch + 1)\n",
    "    writer.add_scalars('Training vs. Validation/Accuracy',\n",
    "                    { 'Training' : acc, 'Validation' : avg_vacc },\n",
    "                    epoch + 1)\n",
    "    #writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'model_{}_{}'.format(timestamp, epoch)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.train(False)\n",
    "preds_test = []\n",
    "for i, vdata in enumerate(test_loader):\n",
    "    vinputs = vdata\n",
    "    voutputs = model(vinputs).detach()\n",
    "    preds_test.extend(voutputs.cpu())\n",
    "preds = np.ones_like(preds_test)\n",
    "preds[np.where(np.array(preds_test)<0.5)] = -1\n",
    "preds = pd.DataFrame(preds)\n",
    "\n",
    "create_csv_submission(preds.index.values.tolist(), np.asarray(preds), 'model_{}_.csv'.format(timestamp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 14:13:03) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bd2e759ece46f7968ecb77e124a003f65bcd7fd10d71dbb77ace05354c0e1a30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
